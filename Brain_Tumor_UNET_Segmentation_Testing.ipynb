{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoQHe03Kt85Mb4gCoU+2+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krish-mal15/Brain-Tumor-Segmentation-IGRT-Algorithms/blob/main/Brain_Tumor_UNET_Segmentation_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "C_eCnbAgE4Uh",
        "outputId": "1ac6c551-24f5-4d13-f980-8621fe582142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixels:  [[ 60 150   0]\n",
            " [ 60 150   1]\n",
            " [ 60 150   2]\n",
            " ...\n",
            " [118 169   0]\n",
            " [118 169   1]\n",
            " [118 169   2]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7fc697aa32b2>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0madd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m   \u001b[0mcat_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ],
      "source": [
        "### Need to upload \"/UNET-tumor-segment-model.keras\" file\n",
        "### Upload test-images as desired\n",
        "\n",
        "# NEED TO TEST IMAGES WIT NO TUMOR AND DISPLAY TEXT IF TUMOR IS NOT DETECTED.\n",
        "# EITHER CHECK IF PIXEL ARRAY (or y_pred) IS EMPTY OR USE DETECTION MODEL (DONT CHANGE TENSORFLOW VERSION)\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "H = 256\n",
        "W = 256\n",
        "\n",
        "\n",
        "model = keras.models.load_model('/UNET-tumor-segment-model.keras')\n",
        "\n",
        "# detection_model = tf.keras.models.load_model('/tumor-detection.keras')\n",
        "# model.summary()\n",
        "\n",
        "x = '/Test-Images/627.png'\n",
        "y = '/Test-Images/627-mask.png'\n",
        "\n",
        "\n",
        "image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "image = cv2.resize(image, (W, H))\n",
        "\n",
        "x = image/255.0\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "mask = cv2.resize(mask, (W, H))\n",
        "\n",
        "y_pred = model.predict(x, verbose=0)[0]\n",
        "y_pred = np.squeeze(y_pred, axis=-1)\n",
        "y_pred = y_pred >= 0.5\n",
        "y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "mask = np.expand_dims(mask, axis=-1)\n",
        "mask = np.concatenate([mask, mask, mask], axis=-1)\n",
        "\n",
        "y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
        "y_pred = y_pred * 255\n",
        "\n",
        "line = np.ones((H, 10, 3)) * 255\n",
        "\n",
        "pixels = np.argwhere(y_pred == 255)\n",
        "print('Pixels: ', pixels)\n",
        "\n",
        "y_pred = y_pred.astype(image.dtype)\n",
        "\n",
        "add = cv2.addWeighted(image, 0.9, y_pred, 0.7, 0.0)\n",
        "\n",
        "cat_images = np.concatenate([image, add], axis=1)\n",
        "\n",
        "cv2_imshow(cat_images)\n",
        "\n",
        "mask = mask/255.0\n",
        "mask = (mask > 0.5).astype(np.int32).flatten()\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "\n",
        "### Will need to create algorithm to locate any desired pixel (maybe use a gui where you can click and it will give coordinated). giving the midpoint wont really do much and may complicate things further\n",
        "### Or when finished researching the specific targeting for the IGRT or steroetactic radiosurgery, just find necessarry points or include the finding points mechanism in the radiotherapy targeting code\n",
        "\n"
      ]
    }
  ]
}